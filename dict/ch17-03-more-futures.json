{
  "Working With Any Number of Futures": {
    "_translate": "<a class=\"header\" href=\"#working-with-any-number-of-futures\">处理任意数量的 Future</a>",
    "_note": ""
  },
  "This is definitely a nice improvement over needing to swap between join and join3 and join4 and so on! However, even this macro form only works when we know the number of futures ahead of time. In real-world Rust, though, pushing futures into a collection and then waiting on some or all the futures in that collection to complete is a common pattern.": {
    "_translate": "这肯定比需要在 <code>join</code> 和 <code>join3</code> 和 <code>join4</code> 等之间切换要好得多！然而，即使这种宏形式也只在我们提前知道未来数量的情况下有效。然而，在现实世界的 Rust 中，将未来推入集合，然后等待该集合中的一些或所有未来完成，是一种常见的模式。",
    "_note": ""
  },
  "When we switched from using two futures to three in the previous section, we also had to switch from using join to using join3. It would be annoying to have to call a different function every time we changed the number of futures we wanted to join. Happily, we have a macro form of join to which we can pass an arbitrary number of arguments. It also handles awaiting the futures itself. Thus, we could rewrite the code from Listing 17-13 to use join! instead of join3, as in Listing 17-14:": {
    "_translate": "当我们从使用两个 future 转变为使用三个 future 时，我们还必须从使用 <code>join</code> 转变为使用 <code>join3</code>。每次我们改变想要连接的 future 数量时，都必须调用不同的函数，这会很烦人。幸运的是，我们有一个宏形式的 <code>join</code>，可以传递任意数量的参数。它还自行处理 future 的等待。因此，我们可以将列表 17-13 中的代码重写为使用 <code>join!</code> 而不是 <code>join3</code>，如列表 17-14 所示：",
    "_note": ""
  },
  "Unfortunately, this doesn’t compile. Instead, we get this error:": {
    "_translate": "不幸的是，这无法编译。相反，我们得到了这个错误：",
    "_note": ""
  },
  "To check all the futures in some collection, we’ll need to iterate over and join on all of them. The trpl::join_all function accepts any type which implements the Iterator trait, which we learned about back in Chapter 13, so it seems like just the ticket. Let’s try putting our futures in a vector, and replace join! with join_all.": {
    "_translate": "要检查集合中的所有 future，我们需要遍历并连接<em>所有</em>的它们。<code>trpl::join_all</code> 函数接受任何实现了 <code>Iterator</code> 特性的类型，我们在第 13 章中学习过，所以它看起来正是我们需要的。让我们尝试将我们的 future 放入一个向量中，并用 <code>join_all</code> 替换 <code>join!</code>。",
    "_note": ""
  },
  "This might be surprising. After all, none of them return anything, so each block produces a Future<Output = ()>. However, Future is a trait, not a concrete type. The concrete types are the individual data structures generated by the compiler for async blocks. You can’t put two different hand-written structs in a Vec, and the same thing applies to the different structs generated by the compiler.": {
    "_translate": "这可能会让人感到惊讶。毕竟，它们都没有返回任何东西，所以每个块都会生成一个<code>Future&lt;Output = ()&gt;</code>。然而，<code>Future</code>是一个特质，而不是一个具体类型。具体类型是由编译器为异步块生成的各个数据结构。你不能将两个不同的手写结构体放入一个<code>Vec</code>中，同样地，也不能将编译器生成的不同结构体放入其中。",
    "_note": ""
  },
  "To make this work, we need to use trait objects, just as we did in “Returning Errors from the run function” in Chapter 12. (We’ll cover trait objects in detail in Chapter 18.) Using trait objects lets us treat each of the anonymous futures produced by these types as the same type, because all of them implement the Future trait.": {
    "_translate": "要使这工作，我们需要使用<em>trait 对象</em>，就像我们在<a href=\"ch12-03-improving-error-handling-and-modularity.html\">“从 run 函数返回错误”</a>第 12 章中所做的那样。（我们将在第 18 章详细讨论 trait 对象。）使用 trait 对象让我们可以将这些类型产生的每个匿名 future 视为同一类型，因为它们都实现了<code>Future</code> trait。",
    "_note": ""
  },
  "Note: In Chapter 8, we discussed another way to include multiple types in a Vec: using an enum to represent each of the different types which can appear in the vector. We can’t do that here, though. For one thing, we have no way to name the different types, because they are anonymous. For another, the reason we reached for a vector and join_all in the first place was to be able to work with a dynamic collection of futures where we don’t know what they will all be until runtime.": {
    "_translate": "注意：在第 8 章中，我们讨论了另一种在 <code>Vec</code> 中包含多种类型的方法：使用枚举来表示向量中可能出现的每种不同类型。然而，我们在这里不能这样做。一方面，我们无法命名这些不同的类型，因为它们是匿名的。另一方面，我们首先选择向量和 <code>join_all</code> 的原因是为了能够处理一个动态的未来集合，直到运行时我们才知道它们会是什么。",
    "_note": ""
  },
  "We start by wrapping each of the futures in the vec! in a Box::new, as shown in Listing 17-16.": {
    "_translate": "我们首先将 <code>vec!</code> 中的每个 future 用 <code>Box::new</code> 包装起来，如清单 17-16 所示。",
    "_note": ""
  },
  "The type we had to write here is a little involved, so let’s walk through it:": {
    "_translate": "我们在这里必须编写的类型有点复杂，所以让我们逐步分析它：",
    "_note": ""
  },
  "That already made a big difference. Now when we run the compiler, we only have the errors mentioning Unpin. Although there are three of them, notice that each is very similar in its contents.": {
    "_translate": "这已经产生了很大的不同。现在当我们运行编译器时，我们只有提到<code>Unpin</code>的错误。虽然有三个，但请注意，每个错误的内容都非常相似。",
    "_note": ""
  },
  "Unfortunately, this still doesn’t compile. In fact, we have the same basic error we did before, but we get one for both the second and third Box::new calls, and we also get new errors referring to the Unpin trait. We will come back to the Unpin errors in a moment. First, let’s fix the type errors on the Box::new calls, by explicitly annotating the type of the futures variable:": {
    "_translate": "不幸的是，这仍然无法编译。事实上，我们遇到了与之前相同的基本错误，但这次在第二个和第三个 <code>Box::new</code> 调用时都出现了错误，同时还有新的错误提到了 <code>Unpin</code> 特性。我们稍后会回到 <code>Unpin</code> 错误。首先，让我们通过显式注解 <code>futures</code> 变量的类型来修复 <code>Box::new</code> 调用的类型错误：",
    "_note": ""
  },
  "If we compile and run this, we finally get the output we hoped for:": {
    "_translate": "如果我们编译并运行这个程序，我们最终会得到我们希望的输出：",
    "_note": ""
  },
  "Phew!": {
    "_translate": "<p>呼！</p>",
    "_note": ""
  },
  "That is a lot to digest, so let’s pull it apart. The first part of the message tell us that the first async block (src/main.rs:8:23: 20:10) does not implement the Unpin trait, and suggests using pin! or Box::pin to resolve it. Later in the chapter, we’ll dig into a few more details about Pin and Unpin. For the moment, though, we can just follow the compiler’s advice to get unstuck! In Listing 17-18, we start by updating the type annotation for futures, with a Pin wrapping each Box. Second, we use Box::pin to pin the futures themselves.": {
    "_translate": "那有<em>很多</em>需要消化的内容，所以我们来拆解一下。消息的第一部分\n告诉我们第一个异步块（<code>src/main.rs:8:23: 20:10</code>）没有\n实现<code>Unpin</code>特质，并建议使用<code>pin!</code>或<code>Box::pin</code>来解决\n它。在本章的后面，我们将深入探讨更多关于<code>Pin</code>和\n<code>Unpin</code>的细节。不过，现在我们只需按照编译器的建议来解决问题！在清单17-18中，我们首先更新\n<code>futures</code>的类型注解，用<code>Pin</code>包裹每个<code>Box</code>。其次，我们使用<code>Box::pin</code>来固定\n这些未来对象。",
    "_note": ""
  },
  "There’s a bit more we can explore here. For one thing, using Pin<Box<T>> comes with a small amount of extra overhead from putting these futures on the heap with Box—and we’re only doing that to get the types to line up. We don’t actually need the heap allocation, after all: these futures are local to this particular function. As noted above, Pin is itself a wrapper type, so we can get the benefit of having a single type in the Vec—the original reason we reached for Box—without doing a heap allocation. We can use Pin directly with each future, using the std::pin::pin macro.": {
    "_translate": "这里还有更多可以探讨的内容。一方面，使用<code>Pin&lt;Box&lt;T&gt;&gt;</code> 会因为使用 <code>Box</code> 将这些 future 放在堆上而带来一些额外的开销——而我们这样做只是为了使类型对齐。毕竟，我们实际上并不 <em>需要</em> 堆分配：这些 future 仅限于这个特定的函数。如上所述，<code>Pin</code> 本身是一个包装类型，因此我们可以在 <code>Vec</code> 中拥有单一类型的好处——这正是我们最初选择 <code>Box</code> 的原因——而无需进行堆分配。我们可以直接使用 <code>Pin</code> 与每个 future，使用 <code>std::pin::pin</code> 宏。",
    "_note": ""
  },
  "However, we must still be explicit about the type of the pinned reference; otherwise Rust will still not know to interpret these as dynamic trait objects, which is what we need them to be in the Vec. We therefore pin! each future when we define it, and define futures as a Vec containing pinned mutable references to the dynamic Future type, as in Listing 17-19.": {
    "_translate": "然而，我们必须明确指出固定引用的类型；否则 Rust 仍然不知道将这些解释为动态特征对象，而这正是我们需要它们在 <code>Vec</code> 中成为的。因此，我们在定义每个未来时都使用 <code>pin!</code>，并将 <code>futures</code> 定义为包含指向动态 <code>Future</code> 类型的固定可变引用的 <code>Vec</code>，如清单 17-19 所示。",
    "_note": ""
  },
  "We got this far by ignoring the fact that we might have different Output types. For example, in Listing 17-20, the anonymous future for a implements Future<Output = u32>, the anonymous future for b implements Future<Output = &str>, and the anonymous future for c implements Future<Output = bool>.": {
    "_translate": "我们通过忽略我们可能有不同的<code>Output</code>类型这一事实才走到这一步。例如，在示例 17-20 中，<code>a</code>的匿名未来实现了<code>Future&lt;Output = u32&gt;</code>，<code>b</code>的匿名未来实现了<code>Future&lt;Output = &amp;str&gt;</code>，<code>c</code>的匿名未来实现了<code>Future&lt;Output = bool&gt;</code>。",
    "_note": ""
  },
  "We can use trpl::join! to await them, because it allows you to pass in multiple future types and produces a tuple of those types. We cannot use trpl::join_all, because it requires the futures passed in all to have the same type. Remember, that error is what got us started on this adventure with Pin!": {
    "_translate": "我们可以使用<code>trpl::join!</code>来等待它们，因为它允许你传入多个未来类型并生成这些类型的元组。我们<em>不能</em>使用<code>trpl::join_all</code>，因为它要求传入的所有未来都具有相同的类型。记住，那个错误是我们开始这次与<code>Pin</code>的冒险的原因！",
    "_note": ""
  },
  "Racing futures": {
    "_translate": "<a class=\"header\" href=\"#racing-futures\">竞速未来</a>",
    "_note": ""
  },
  "This is a fundamental tradeoff: we can either deal with a dynamic number of futures with join_all, as long as they all have the same type, or we can deal with a set number of futures with the join functions or the join! macro, even if they have different types. This is the same as working with any other types in Rust, though. Futures are not special, even though we have some nice syntax for working with them, and that is a good thing.": {
    "_translate": "这是一个基本的权衡：我们可以使用<code>join_all</code>处理动态数量的未来对象，只要它们都具有相同的类型，或者我们可以使用<code>join</code>函数或<code>join!</code>宏处理固定数量的未来对象，即使它们具有不同的类型。这与在Rust中处理任何其他类型是一样的。未来对象并不特殊，尽管我们有一些不错的语法来处理它们，这是一件好事。",
    "_note": ""
  },
  "When we “join” futures with the join family of functions and macros, we require all of them to finish before we move on. Sometimes, though, we only need some future from a set to finish before we move on—kind of similar to racing one future against another.": {
    "_translate": "当我们使用 <code>join</code> 系列函数和宏“连接”未来值时，我们要求 <em>所有</em> 未来值都完成之后才继续前进。然而，有时我们只需要 <em>某些</em> 未来值从一组中完成之后就可以继续前进——有点类似于让一个未来值与另一个未来值竞赛。",
    "_note": ""
  },
  "Notice that if you flip the order of the arguments to race, the order of the “started” messages changes, even though the fast future always completes first. That’s because the implementation of this particular race function is not fair. It always runs the futures passed as arguments in the order they’re passed. Other implementations are fair, and will randomly choose which future to poll first. Regardless of whether the implementation of race we’re using is fair, though, one of the futures will run up to the first await in its body before another task can start.": {
    "_translate": "请注意，如果你调换 <code>race</code> 函数参数的顺序，“started” 消息的顺序也会改变，即使 <code>fast</code> 未来总是首先完成。这是因为这个特定的 <code>race</code> 函数的实现是不公平的。它总是按照参数传递的顺序运行传递的未来。其他实现 <em>是</em> 公平的，会随机选择首先轮询哪个未来。然而，无论我们使用的 <code>race</code> 实现是否公平，<em>一个</em> 未来将在另一个任务开始之前运行到其主体中的第一个 <code>await</code>。",
    "_note": ""
  },
  "In Listing 17-21, we once again use trpl::race to run two futures, slow and fast, against each other. Each one prints a message when it starts running, pauses for some amount of time by calling and awaiting sleep, and then prints another message when it finishes. Then we pass both to trpl::race and wait for one of them to finish. (The outcome here won’t be too surprising: fast wins!) Unlike when we used race back in Our First Async Program, we just ignore the Either instance it returns here, because all of the interesting behavior happens in the body of the async blocks.": {
    "_translate": "在清单 17-21 中，我们再次使用 <code>trpl::race</code> 来运行两个未来，<code>slow</code> 和 <code>fast</code>，彼此竞争。每个未来在开始运行时打印一条消息，通过调用并等待 <code>sleep</code> 暂停一段时间，然后在完成时打印另一条消息。然后我们将两者传递给 <code>trpl::race</code> 并等待其中一个完成。（这里的结局不会太令人惊讶：<code>fast</code> 赢了！）与我们在 <a href=\"ch17-01-futures-and-syntax.html#our-first-async-program\">我们的第一个异步程序</a> 中使用 <code>race</code> 时不同，这里我们只是忽略它返回的 <code>Either</code> 实例，因为所有有趣的行为都发生在异步块的主体中。",
    "_note": ""
  },
  "Recall from Our First Async Program that at each await point, Rust gives a runtime a chance to pause the task and switch to another one if the future being awaited isn’t ready. The inverse is also true: Rust only pauses async blocks and hands control back to a runtime at an await point. Everything between await points is synchronous.": {
    "_translate": "回想 <a href=\"ch17-01-futures-and-syntax.html#our-first-async-program\">我们的第一个异步程序</a> 中，在每个 await 点，Rust 会给运行时一个机会，如果正在等待的未来值尚未准备好，可以暂停任务并切换到另一个任务。相反的情况也成立：Rust <em>仅</em> 在 await 点暂停异步块并将控制权交还给运行时。await 点之间的所有内容都是同步的。",
    "_note": ""
  },
  "That means if you do a bunch of work in an async block without an await point, that future will block any other futures from making progress. You may sometimes hear this referred to as one future starving other futures. In some cases, that may not be a big deal. However, if you are doing some kind of expensive setup or long-running work, or if you have a future which will keep doing some particular task indefinitely, you’ll need to think about when and where to hand control back to the runtime.": {
    "_translate": "这意味着，如果你在一个异步块中进行大量工作而没有 await 点，\n该未来将阻止其他未来取得进展。你有时可能会听到这种情况被称为一个未来 <em>饿死</em> 其他未来。在某些情况下，\n这可能不是什么大问题。然而，如果你正在进行某种昂贵的设置或长时间运行的工作，或者如果你有一个将无限期地继续执行某项特定任务的未来，你将需要考虑何时以及在哪里\n将控制权交还给运行时。",
    "_note": ""
  },
  "By the same token, if you have long-running blocking operations, async can be a useful tool for providing ways for different parts of the program to relate to each other.": {
    "_translate": "同样地，如果你有长时间运行的阻塞操作，异步可以是一个有用的工具，为程序的不同部分提供相互关联的方式。",
    "_note": ""
  },
  "But how would you hand control back to the runtime in those cases?": {
    "_translate": "但是在这些情况下，你<em>如何</em>将控制权交还给运行时？",
    "_note": ""
  },
  "Yielding": {
    "_translate": "<a class=\"header\" href=\"#yielding\">生成</a>",
    "_note": ""
  },
  "In Listing 17-23, we use slow to emulate doing this kind of CPU-bound work in a pair of futures. To begin, each future only hands control back to the runtime after carrying out a bunch of slow operations.": {
    "_translate": "在清单 17-23 中，我们使用 <code>slow</code> 来模拟在一对 future 中执行这种 CPU 密集型工作。首先，每个 future 只有在执行了一堆慢操作 <em>之后</em> 才将控制权交还给运行时。",
    "_note": ""
  },
  "Let’s simulate a long-running operation. Listing 17-22 introduces a slow function. It uses std::thread::sleep instead of trpl::sleep so that calling slow will block the current thread for some number of milliseconds. We can use slow to stand in for real-world operations which are both long-running and blocking.": {
    "_translate": "让我们模拟一个长时间运行的操作。列表 17-22 引入了一个 <code>slow</code> 函数。它使用 <code>std::thread::sleep</code> 而不是 <code>trpl::sleep</code>，因此调用 <code>slow</code> 将会阻塞当前线程一段时间（以毫秒为单位）。我们可以使用 <code>slow</code> 来代表那些既长时间运行又阻塞的现实操作。",
    "_note": ""
  },
  "If you run this, you will see this output:": {
    "_translate": "如果您运行此代码，您将看到以下输出：",
    "_note": ""
  },
  "We can already see this kind of handoff happening in Listing 17-23: if we removed the trpl::sleep at the end of the a future, it would complete without the b future running at all. Maybe we could use the sleep function as a starting point?": {
    "_translate": "我们已经可以在清单 17-23 中看到这种交接的发生：如果我们移除 <code>a</code> 未来末尾的 <code>trpl::sleep</code>，它将在 <code>b</code> 未来完全不运行的情况下完成。也许我们可以将 <code>sleep</code> 函数作为起点？",
    "_note": ""
  },
  "As with our earlier example, race still finishes as soon as a is done. There’s no interleaving between the two futures, though. The a future does all of its work until the trpl::sleep call is awaited, then the b future does all of its work until its own trpl::sleep call is awaited, and then the a future completes. To allow both futures to make progress between their slow tasks, we need await points so we can hand control back to the runtime. That means we need something we can await!": {
    "_translate": "与我们之前的例子一样，<code>race</code> 仍然在 <code>a</code> 完成时结束。\n不过，这两个未来之间没有交错。<code>a</code> 未来在其 <code>trpl::sleep</code> 调用被等待之前完成所有工作，然后 <code>b</code> 未来在其自己的 <code>trpl::sleep</code> 调用被等待之前完成所有工作，最后 <code>a</code> 未来完成。为了在它们的慢任务之间让两个未来都能取得进展，我们需要等待点，以便我们可以将控制权交还给运行时。这意味着我们需要一些可以等待的东西！",
    "_note": ""
  },
  "In Listing 17-24, we add trpl::sleep calls with await points between each call to slow. Now the two futures’ work is interleaved:": {
    "_translate": "在清单 17-24 中，我们在每次调用 <code>slow</code> 之间添加了带有 await 点的 <code>trpl::sleep</code> 调用。现在两个未来的任务是交错进行的：",
    "_note": ""
  },
  "The a future still runs for a bit before handing off control to b, because it calls slow before ever calling trpl::sleep, but after that the futures swap back and forth each time one of them hits an await point. In this case, we have done that after every call to slow, but we could break up the work however makes the most sense to us.": {
    "_translate": "<code>a</code> 未来在将控制权交给 <code>b</code> 之前仍然运行一段时间，因为它在调用 <code>trpl::sleep</code> 之前先调用了 <code>slow</code>，但在那之后，每当其中一个到达 await 点时，这些未来就会来回交换。在这种情况下，我们在每次调用 <code>slow</code> 之后都这样做了，但我们可以根据自己的需要以任何最合理的方式分配工作。",
    "_note": ""
  },
  "We don’t really want to sleep here, though: we want to make progress as fast as we can. We just need to hand back control to the runtime. We can do that directly, using the yield_now function. In Listing 17-25, we replace all those sleep calls with yield_now.": {
    "_translate": "我们并不真的想在这里<em>睡眠</em>：我们希望尽可能快地取得进展。我们只需要将控制权交还给运行时。我们可以直接使用<code>yield_now</code>函数来实现。在清单17-25中，我们将所有那些<code>sleep</code>调用替换为<code>yield_now</code>。",
    "_note": ""
  },
  "This is both clearer about the actual intent and can be significantly faster than using sleep, because timers such as the one used by sleep often have limits to how granular they can be. The version of sleep we are using, for example, will always sleep for at least a millisecond, even if we pass it a Duration of one nanosecond. Again, modern computers are fast: they can do a lot in one millisecond!": {
    "_translate": "这既更清楚地表达了实际意图，也可以比使用<code>sleep</code>显著更快，因为像<code>sleep</code>所使用的计时器通常有其粒度限制。例如，我们正在使用的<code>sleep</code>版本，即使我们传递一个<code>Duration</code>为一纳秒，它也会至少休眠一毫秒。同样，现代计算机<em>很快</em>：它们在一毫秒内可以完成很多事情！",
    "_note": ""
  },
  "The version with yield_now is way faster!": {
    "_translate": "带有 <code>yield_now</code> 的版本 <em>快得多</em>！",
    "_note": ""
  },
  "You can see this for yourself by setting up a little benchmark, such as the one in Listing 17-26. (This isn’t an especially rigorous way to do performance testing, but it suffices to show the difference here.) Here, we skip all the status printing, pass a one-nanosecond Duration to trpl::sleep, and let each future run by itself, with no switching between the futures. Then we run for 1,000 iterations and see how long the future using trpl::sleep takes compared to the future using trpl::yield_now.": {
    "_translate": "你可以通过设置一个小基准测试来自己查看，例如列表 17-26 中的基准测试。（这并不是一种特别严谨的性能测试方法，但足以显示这里的差异。）在这里，我们跳过所有状态打印，将一个纳秒的<code>Duration</code>传递给<code>trpl::sleep</code>，并让每个未来单独运行，不在这两个未来之间切换。然后我们运行 1,000 次迭代，看看使用<code>trpl::sleep</code>的未来与使用<code>trpl::yield_now</code>的未来相比需要多长时间。",
    "_note": ""
  },
  "This means that async can be useful even for compute-bound tasks, depending on what else your program is doing, because it provides a useful tool for structuring the relationships between different parts of the program. This is a form of cooperative multitasking, where each future has the power to determine when it hands over control via await points. Each future therefore also has the responsibility to avoid blocking for too long. In some Rust-based embedded operating systems, this is the only kind of multitasking!": {
    "_translate": "这意味着，即使对于计算密集型任务，async 也可以非常有用，这取决于程序的其他部分在做什么，因为它提供了一种有用的工具来结构化程序不同部分之间的关系。这是一种 <em>协作式多任务处理</em>，每个 future 都有权决定何时通过 await 点交出控制权。因此，每个 future 也有责任避免阻塞时间过长。在某些基于 Rust 的嵌入式操作系统中，这是 <em>唯一</em> 的多任务处理方式！",
    "_note": ""
  },
  "In real-world code, you won’t usually be alternating function calls with await points on every single line, of course. While yielding control in this way is relatively inexpensive, it’s not free! In many cases, trying to break up a compute-bound task might make it significantly slower, so sometimes it’s better for overall performance to let an operation block briefly. You should always measure to see what your code’s actual performance bottlenecks are. The underlying dynamic is an important one to keep in mind if you are seeing a lot of work happening in serial that you expected to happen concurrently, though!": {
    "_translate": "在实际代码中，你通常不会在每一行代码中交替使用函数调用和 await\n点，当然。虽然以这种方式让出控制权相对便宜，但并不是免费的！在许多情况下，尝试将计算密集型任务分解可能会使其显著变慢，因此有时为了 <em>整体</em> 性能，让一个操作短暂阻塞会更好。你应该始终测量以了解代码的实际性能瓶颈是什么。然而，如果你确实看到很多你期望并发执行的工作实际上是串行进行的，那么底层的动态是一个重要的考虑因素！",
    "_note": ""
  },
  "Building Our Own Async Abstractions": {
    "_translate": "<a class=\"header\" href=\"#building-our-own-async-abstractions\">构建我们自己的异步抽象</a>",
    "_note": ""
  },
  "We can also compose futures together to create new patterns. For example, we can build a timeout function with async building blocks we already have. When we’re done, the result will be another building block we could use to build up yet further async abstractions.": {
    "_translate": "我们还可以将未来组合在一起以创建新的模式。例如，我们可以\n使用我们已经拥有的异步构建块来构建一个<code>timeout</code>函数。当我们完成时，结果将是一个我们可以用来构建\n更进一步的异步抽象的构建块。",
    "_note": ""
  },
  "Listing 17-27 shows how we would expect this timeout to work with a slow future.": {
    "_translate": "列表 17-27 显示了我们期望这个 <code>timeout</code> 如何与一个慢的未来一起工作。",
    "_note": ""
  },
  "Let’s implement this! To begin, let’s think about the API for timeout:": {
    "_translate": "让我们来实现这个！首先，让我们思考一下 <code>timeout</code> 的 API：",
    "_note": ""
  },
  "Listing 17-28 shows this declaration.": {
    "_translate": "列表 17-28 显示了此声明。",
    "_note": ""
  },
  "That satisfies our goals for the types. Now let’s think about the behavior we need: we want to race the future passed in against the duration. We can use trpl::sleep to make a timer future from the duration, and use trpl::race to run that timer with the future the caller passes in.": {
    "_translate": "这满足了我们对类型的要求。现在让我们考虑需要的<em>行为</em>：我们希望将传入的未来与持续时间进行竞赛。我们可以使用<code>trpl::sleep</code>从持续时间创建一个计时器未来，并使用<code>trpl::race</code>来运行计时器与调用者传入的未来。",
    "_note": ""
  },
  "We also know that race is not fair, and polls arguments in the order they are passed. Thus, we pass future_to_try to race first so it gets a chance to complete even if max_time is a very short duration. If future_to_try finishes first, race will return Left with the output from future. If timer finishes first, race will return Right with the timer’s output of ().": {
    "_translate": "我们也知道 <code>race</code> 是不公平的，并且按照传递的顺序轮询参数。因此，我们首先将 <code>future_to_try</code> 传递给 <code>race</code>，以便即使 <code>max_time</code> 是一个非常短的持续时间，它也有机会完成。如果 <code>future_to_try</code> 首先完成，<code>race</code> 将返回 <code>Left</code>，并带有 <code>future</code> 的输出。如果 <code>timer</code> 首先完成，<code>race</code> 将返回 <code>Right</code>，并带有计时器的输出 <code>()</code>。",
    "_note": ""
  },
  "In Listing 17-29, we match on the result of awaiting trpl::race. If the future_to_try succeeded and we get a Left(output), we return Ok(output). If the sleep timer elapsed instead and we get a Right(()), we ignore the () with _ and return Err(max_time) instead.": {
    "_translate": "在清单 17-29 中，我们匹配 <code>trpl::race</code> 的结果。如果 <code>future_to_try</code> 成功并且我们得到一个 <code>Left(output)</code>，我们返回 <code>Ok(output)</code>。如果睡眠计时器到期并且我们得到一个 <code>Right(())</code>，我们使用 <code>_</code> 忽略 <code>()</code> 并返回 <code>Err(max_time)</code>。",
    "_note": ""
  },
  "With that, we have a working timeout, built out of two other async helpers. If we run our code, it will print the failure mode after the timeout:": {
    "_translate": "至此，我们已经用两个其他异步助手构建了一个可用的<code>timeout</code>。如果\n我们运行我们的代码，它将在超时后打印失败模式：",
    "_note": ""
  },
  "Because futures compose with other futures, you can build really powerful tools using smaller async building blocks. For example, you can use this same approach to combine timeouts with retries, and in turn use those with things such as network calls—one of the examples from the beginning of the chapter!": {
    "_translate": "因为 Future 可以与其他 Future 组合，所以你可以使用较小的异步构建块来构建非常强大的工具。例如，你可以使用相同的方法将超时与重试结合起来，然后将这些与网络调用等事物结合使用——这是本章开头的一个例子！",
    "_note": ""
  },
  "We’ve now seen a number of ways to work with multiple futures at the same time. Up next, we’ll look at how we can work with multiple futures in a sequence over time, with streams. Here are a couple more things you might want to consider first, though:": {
    "_translate": "我们现在看到了同时处理多个未来的几种方法。接下来，我们将看看如何随着时间在一个序列中处理多个未来，使用<em>流</em>。不过，在此之前，这里还有几件你可能想要先考虑的事情：",
    "_note": ""
  },
  "In practice, you will usually work directly with async and await, and secondarily with functions and macros such as join, join_all, race, and so on. You’ll only need to reach for pin now and again to use them with those APIs.": {
    "_translate": "在实际中，你通常会直接使用 <code>async</code> 和 <code>await</code>，其次会使用诸如 <code>join</code>、<code>join_all</code>、<code>race</code> 等函数和宏。你只需要偶尔使用 <code>pin</code> 来与这些 API 一起使用。",
    "_note": ""
  },
  "We used a Vec with join_all to wait for all of the futures in some group to finish. How could you use a Vec to process a group of futures in sequence, instead? What are the tradeoffs of doing that?": {
    "_translate": "我们使用了 <code>Vec</code> 和 <code>join_all</code> 来等待某组中所有未来的完成。你如何使用 <code>Vec</code> 来按顺序处理一组未来的？这样做有什么权衡？",
    "_note": ""
  },
  "Take a look at the futures::stream::FuturesUnordered type from the futures crate. How would using it be different from using a Vec? (Don’t worry about the fact that it is from the stream part of the crate; it works just fine with any collection of futures.)": {
    "_translate": "查看 <code>futures::stream::FuturesUnordered</code> 类型，来自 <code>futures</code> 库。使用它与使用 <code>Vec</code> 有什么不同？（不要担心它是来自库的 <code>stream</code> 部分；它可以很好地与任何未来的集合一起使用。）",
    "_note": ""
  },
  "Working With Any Number of Futures - The Rust Programming Language": {
    "_translate": "处理任意数量的 Future - 《Rust 编程语言》",
    "_note": ""
  }
}