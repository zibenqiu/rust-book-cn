{
  "Futures, Tasks, and Threads": {
    "_translate": "<a class=\"header\" href=\"#futures-tasks-and-threads\">Futures, 任务和线程</a>",
    "_note": ""
  },
  "As we saw in the previous chapter, threads provide one approach to concurrency. We’ve seen another approach to concurrency in this chapter, using async with futures and streams. You might be wondering why you would choose one or the other. The answer is: it depends! And in many cases, the choice isn’t threads or async but rather threads and async.": {
    "_translate": "正如我们在上一章中看到的，线程提供了一种实现并发的方法。\n在本章中，我们看到了另一种使用 async 与 futures 和 streams 实现并发的方法。你可能会想知道为什么要在其中选择一种。答案是：这取决于具体的情况！在许多情况下，选择不是线程 <em>或</em> 异步，而是线程 <em>和</em> 异步。",
    "_note": ""
  },
  "The async model provides a different—and ultimately complementary—set of tradeoffs. In the async model, concurrent operations don’t require their own threads. Instead, they can run on tasks, as when we used trpl::spawn_task to kick off work from a synchronous function throughout the streams section. A task is similar to a thread, but instead of being managed by the operating system, it’s managed by library-level code: the runtime.": {
    "_translate": "异步模型提供了一组不同且最终互补的权衡。在异步模型中，并发操作不需要自己的线程。相反，它们可以在任务上运行，就像我们在流部分中使用<code>trpl::spawn_task</code>从同步函数启动工作一样。任务类似于线程，但不是由操作系统管理，而是由库级别的代码：运行时管理。",
    "_note": ""
  },
  "Many operating systems have supplied threading-based concurrency models for decades now, and many programming languages have support for them as a result. However, they are not without their tradeoffs. On many operating systems, they use a fair bit of memory for each thread, and they come with some overhead for starting up and shutting down. Threads are also only an option when your operating system and hardware support them! Unlike mainstream desktop and mobile computers, some embedded systems don’t have an OS at all, so they also don’t have threads!": {
    "_translate": "许多操作系统多年来一直提供基于线程的并发模型，许多编程语言也因此支持它们。然而，它们并非没有权衡。在许多操作系统中，每个线程都会占用相当多的内存，并且启动和关闭时会带来一些开销。线程也仅在你的操作系统和硬件支持时才是一种选择！与主流的桌面和移动计算机不同，一些嵌入式系统根本没有操作系统，因此它们也没有线程！",
    "_note": ""
  },
  "If you run this, the output is identical. And notice how little changes here from the perspective of the calling code! What’s more, even though one of our functions spawned an async task on the runtime and the other spawned an OS thread, the resulting streams were unaffected by the differences.": {
    "_translate": "如果你运行这个，输出是相同的。并且注意，从调用代码的角度来看，这里的变化是多么小！更重要的是，即使我们的一个函数在运行时启动了一个异步任务，而另一个启动了一个操作系统线程，最终的流也没有受到这些差异的影响。",
    "_note": ""
  },
  "Despite the similarities, these two approaches behave very differently, although we might have a hard time measuring it in this very simple example. We could spawn millions of async tasks on any modern personal computer. If we tried to do that with threads, we would literally run out of memory!": {
    "_translate": "尽管有这些相似之处，但这两种方法的行为却大不相同，尽管在这样一个非常简单的例子中我们可能很难测量出来。我们可以在任何现代个人计算机上生成数百万个异步任务。如果我们尝试用线程来做这件事，我们实际上会耗尽内存！",
    "_note": ""
  },
  "In the previous section, we saw that we could build a Stream by using an async channel and spawning an async task which we could call from synchronous code. We could do the exact same thing with a thread! In Listing 17-40, we used trpl::spawn_task and trpl::sleep. In Listing 17-41, we replace those with the thread::spawn and thread::sleep APIs from the standard library in the get_intervals function.": {
    "_translate": "在上一节中，我们看到可以通过使用异步通道和生成一个可以从同步代码调用的异步任务来构建一个<code>Stream</code>。我们也可以用线程来做同样的事情！在清单 17-40 中，我们使用了<code>trpl::spawn_task</code>和<code>trpl::sleep</code>。在清单 17-41 中，我们用标准库中的<code>thread::spawn</code>和<code>thread::sleep</code>API 替换了这些，在<code>get_intervals</code>函数中。",
    "_note": ""
  },
  "This doesn’t mean that async tasks are always better than threads, any more than that threads are always better than tasks.": {
    "_translate": "这并不意味着异步任务总是优于线程，就像线程并不总是优于任务一样。",
    "_note": ""
  },
  "However, there’s a reason these APIs are so similar. Threads act as a boundary for sets of synchronous operations; concurrency is possible between threads. Tasks act as a boundary for sets of asynchronous operations; concurrency is possible both between and within tasks, because a task can switch between futures in its body. Finally, futures are Rust’s most granular unit of concurrency, and each future may represent a tree of other futures. The runtime—specifically, its executor—manages tasks, and tasks manage futures. In that regard, tasks are similar to lightweight, runtime-managed threads with added capabilities that come from being managed by a runtime instead of by the operating system.": {
    "_translate": "然而，这些 API 如此相似是有原因的。线程作为一组同步操作的边界；并发可以在<em>线程之间</em>发生。任务作为一组<em>异步</em>操作的边界；并发既可以在<em>任务之间</em>也可以在<em>任务内部</em>发生，因为任务可以在其主体中切换不同的未来。最后，未来是 Rust 中最细粒度的并发单元，每个未来可能代表其他未来的树。运行时——具体来说，其执行器——管理任务，而任务管理未来。在这方面，任务类似于轻量级的、运行时管理的线程，具有来自运行时管理的额外功能，而不是由操作系统管理。",
    "_note": ""
  },
  "Concurrency with threads is in some ways a simpler programming model than concurrency with async. That can be a strength or a weakness. Threads are somewhat “fire and forget,” they have no native equivalent to a future, so they simply run to completion, without interruption except by the operating system itself. That is, they have no built-in support for intra-task concurrency the way futures do. Threads in Rust also have no mechanisms for cancellation—a subject we haven’t covered in depth in this chapter, but which is implicit in the fact that whenever we ended a future, its state got cleaned up correctly.": {
    "_translate": "并发使用线程在某些方面比使用<code>async</code>的并发模型更简单。这可以是优点也可以是缺点。线程 somewhat “fire and forget”，它们没有类似未来的原生等效物，因此它们只是运行到完成，除非被操作系统本身中断，否则不会中断。也就是说，它们没有像未来那样对<em>任务内并发</em>的内置支持。Rust 中的线程也没有取消机制——这个主题我们在本章中没有深入讨论，但隐含在我们每次结束一个未来时，其状态都会正确清理的事实中。",
    "_note": ""
  },
  "These limitations also make threads harder to compose than futures. It’s much more difficult, for example, to use threads to build helpers such as the timeout we built in “Building Our Own Async Abstractions” or the throttle method we used with streams in “Composing Streams”. The fact that futures are richer data structures means they can be composed together more naturally, as we have seen.": {
    "_translate": "这些限制也使得线程比未来（futures）更难以组合。例如，使用线程构建如我们在<a href=\"ch17-03-more-futures.html#building-our-own-async-abstractions\">“构建我们自己的异步抽象”</a>中构建的<code>timeout</code>，或在<a href=\"ch17-04-streams.html#composing-streams\">“组合流”</a>中使用的<code>throttle</code>方法要困难得多。由于未来（futures）是更丰富的数据结构，这意味着它们可以更自然地组合在一起，正如我们所见。",
    "_note": ""
  },
  "As a default way of thinking about which to use when:": {
    "_translate": "作为默认的思维方式，关于何时使用哪个：",
    "_note": ""
  },
  "Tasks then give additional control over futures, allowing you to choose where and how to group the futures. And it turns out that threads and tasks often work very well together, because tasks can (at least in some runtimes) be moved around between threads. We haven’t mentioned it up until now, but under the hood the Runtime we have been using, including the spawn_blocking and spawn_task functions, is multithreaded by default! Many runtimes use an approach called work stealing to transparently move tasks around between threads based on the current utilization of the threads, with the aim of improving the overall performance of the system. To build that actually requires threads and tasks, and therefore futures.": {
    "_translate": "任务然后提供对未来的<em>额外</em>控制，允许你选择在哪里以及如何分组未来的任务。事实证明，线程和任务通常可以很好地一起工作，因为任务（至少在某些运行时中）可以在线程之间移动。直到现在我们还没有提到，但我们在使用的<code>Runtime</code>，包括<code>spawn_blocking</code>和<code>spawn_task</code>函数，默认情况下是多线程的！许多运行时使用一种称为<em>工作窃取</em>的方法，根据线程的当前利用率透明地在各线程之间移动任务，以提高系统的整体性能。构建这一点实际上需要线程<em>和</em>任务，因此需要未来的任务。",
    "_note": ""
  },
  "And if you need some mix of parallelism and concurrency, you don’t have to choose between threads and async. You can use them together freely, letting each one serve the part it is best at. For example, Listing 17-42 shows a fairly common example of this kind of mix in real-world Rust code.": {
    "_translate": "而且，如果你需要一些并行性和并发性的混合，你不必在线程和异步之间做出选择。你可以自由地将它们一起使用，让每个部分发挥其最擅长的作用。例如，列表 17-42 展示了这种混合在实际的 Rust 代码中一个相当常见的例子。",
    "_note": ""
  },
  "To return to the examples we opened the chapter with: you could imagine running a set of video encoding tasks using a dedicated thread, because video encoding is compute bound, but notifying the UI that those operations are done with an async channel. Examples of this kind of mix abound!": {
    "_translate": "回到我们在本章开头的例子：你可以想象使用一个专用线程来运行一系列视频编码任务，因为视频编码是计算密集型的，但使用异步通道通知UI这些操作已完成。这种混合的例子比比皆是！",
    "_note": ""
  },
  "We begin by creating an async channel. Then we spawn a thread which takes ownership of the sender side of the channel. Within the thread, we send the numbers 1 through 10, and sleep for a second in between each. Finally, we run a future created with an async block passed to trpl::run just as we have throughout the chapter. In that future, we await those messages, just as in the other message-passing examples we have seen.": {
    "_translate": "我们首先创建一个异步通道。然后我们启动一个线程，该线程获取通道的发送端的所有权。在线程内，我们发送数字1到10，并在每次发送之间休眠一秒钟。最后，我们运行一个使用异步块传递给<code>trpl::run</code>创建的未来，就像我们在本章中所做的那样。在那个未来中，我们等待那些消息，就像在我们见过的其他消息传递示例中一样。",
    "_note": ""
  },
  "Summary": {
    "_translate": "<a class=\"header\" href=\"#summary\">摘要</a>",
    "_note": ""
  },
  "This isn’t the last you’ll see of concurrency in this book: the project in Chapter 21 will use the concepts in this chapter in a more realistic situation than the smaller examples discussed here—and compare more directly what it looks like to solve these kinds of problems with threading vs. with tasks and futures.": {
    "_translate": "这不是你在本书中最后一次看到并发：第 21 章的项目将使用本章中的概念，在比这里讨论的较小示例更现实的情况下——并更直接地比较使用线程与使用任务和未来的解决这些问题的样子。",
    "_note": ""
  },
  "Whether with threads, with futures and tasks, or with the combination of them all, Rust gives you the tools you need to write safe, fast, concurrent code—whether for a high-throughput web server or an embedded operating system.": {
    "_translate": "无论是使用线程、使用未来和任务，还是将它们全部结合使用，Rust 都为您提供编写安全、快速、并发代码所需的工具——无论是用于高吞吐量的 Web 服务器还是嵌入式操作系统。",
    "_note": ""
  },
  "Next, we’ll talk about idiomatic ways to model problems and structure solutions as your Rust programs get bigger. In addition, we’ll discuss how Rust’s idioms relate to those you might be familiar with from object-oriented programming.": {
    "_translate": "接下来，我们将讨论随着您的 Rust 程序变得更大，如何以惯用的方式建模问题和结构化解决方案。此外，我们还将讨论 Rust 的惯用法与您可能熟悉的面向对象编程的惯用法之间的关系。",
    "_note": ""
  },
  "Futures, Tasks, and Threads - The Rust Programming Language": {
    "_translate": "Futures, Tasks, and Threads - The Rust Programming Language 未来、任务和线程 - Rust 编程语言",
    "_note": ""
  },
  "If the work is very parallelizable, such as processing a bunch of data where each part can be processed separately, threads are a better choice.": {
    "_translate": "如果工作是<em>非常并行的</em>，比如处理可以分别处理的数据集，线程是更好的选择。",
    "_note": ""
  },
  "If the work is very concurrent, such as handling messages from a bunch of different sources which may come in a different intervals or different rates, async is a better choice.": {
    "_translate": "如果工作是<em>非常并发的</em>，例如处理来自许多不同来源的消息，这些消息可能以不同的间隔或不同的速率到达，那么异步是一个更好的选择。",
    "_note": ""
  }
}